# ğŸš€ Quick Start: LM Studio + AgroSmart Chatbot

## 30-Second Setup

### 1. Download LM Studio
ğŸ‘‰ **https://lmstudio.ai** â†’ Click Download â†’ Install

### 2. Get LLaMA 2 Model
In LM Studio:
- Click **ğŸ” Search**
- Type: `llama-2-7b-chat`
- Download: **TheBloke/Llama-2-7B-Chat-GGUF**
- Choose: **Q4_K_M** (recommended)

### 3. Start the AI
- Click **ğŸ’¬ Chat** tab
- Load your downloaded model
- Click **â†” Local Server** tab
- Click **Start Server** (green button)

### 4. Run AgroSmart
```powershell
# Terminal 1 - Backend
cd C:\Users\Jason Dsouza\Desktop\crop_project
.\venv\Scripts\python.exe prediction_server.py

# Terminal 2 - Frontend
cd C:\Users\Jason Dsouza\Desktop\crop_project\frontend
npm run dev
```

### 5. Chat!
Open `http://localhost:8080` â†’ Click chat icon â†’ Ask questions!

---

## âœ… Checklist

- [ ] LM Studio installed
- [ ] LLaMA 2 7B downloaded
- [ ] Model loaded in Chat tab
- [ ] Server running (port 1234)
- [ ] Flask backend started (port 5000)
- [ ] Frontend running (port 8080)
- [ ] Chatbot responding!

---

## ğŸ¯ Test Questions

Try these in your chatbot:
- "Should I water my crops right now?"
- "What fertilizer do you recommend?"
- "Is the temperature good for my crops?"
- "How can I improve soil moisture?"

---

## âš¡ Why LM Studio?

âœ… **Easy** - Beautiful GUI, no commands
âœ… **Visual** - See everything happening
âœ… **Fast** - GPU acceleration built-in
âœ… **Free** - No API costs
âœ… **Private** - 100% local

---

## ğŸ†˜ Problems?

### Server won't start?
- Check if port 1234 is free
- Restart LM Studio
- Try loading model again

### No AI response?
- Is Flask running? Check terminal
- Is LM Studio server green?
- Is a model loaded?

### Too slow?
- Enable GPU in Settings (if NVIDIA GPU)
- Use Q4_K_M model (not Q8_0)
- Close other apps

---

## ğŸ“– More Help

- **Full Guide:** `LMSTUDIO_SETUP.md`
- **Features:** `CHATBOT_README.md`
- **Test:** Run `test_chatbot.py`

---

**That's it! You now have an AI agricultural assistant running locally!** ğŸŒ±ğŸ¤–
